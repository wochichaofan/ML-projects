{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d2b4c71-3a30-4109-ab6e-7be964847b4e",
   "metadata": {},
   "source": [
    "# Prepare the data\n",
    "\n",
    "Divide onto train, train-valid and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6ef5b44-bdae-4302-8ada-7b8f9161df1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, os, numpy as np\n",
    "\n",
    "import torch, torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e21beb03-eecc-43eb-8805-eec15f8d66a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = 'DogsVsCats/'\n",
    "train_root = data_root+'train/'\n",
    "# train_valid_root = data_root+'train-valid/'\n",
    "test_root = data_root+'test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af0a4e0e-27d3-492f-ab5a-f6cd6946aada",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(train_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccc1c89-075a-4a4d-b647-68fb4e1db132",
   "metadata": {},
   "source": [
    "#### Define torch Datasets and transforms for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6672e6e-72cb-46e6-aed5-2024fe48b055",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c163bc5a-dbf1-4bfe-95e3-92fc826e1d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(IMG_SIZE),\n",
    "    torchvision.transforms.AutoAugment(),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(IMG_SIZE),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(train_root, transform=train_transform)\n",
    "# train_valid_dataset = torchvision.datasets.ImageFolder(train_valid_root, transform=train_transform)\n",
    "test_dataset = torchvision.datasets.ImageFolder(test_root, transform=test_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774233c1-3729-4a5e-a3eb-9b65f84a32d7",
   "metadata": {},
   "source": [
    "#### Make loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0d51bc7-fbe4-4cae-bdc9-83d96c597383",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, pin_memory=True)\n",
    "\n",
    "# train_valid_loader = torch.utils.data.DataLoader(train_valid_dataset, batch_size=32, shuffle=True, pin_memory=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a7de2c-a1ad-4623-91b4-dc59b1ef4849",
   "metadata": {},
   "source": [
    "# Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "153c0412-d53c-4e91-9b80-964ff1599486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torchvision.models import resnet18 as model, ResNet18_Weights as model_weights\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "# resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df8bbf3e-8134-4b62-a947-825eabac38ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class finalLayer(torch.nn.Module):\n",
    "    def __init__(self, features_in):\n",
    "        super(finalLayer, self).__init__()\n",
    "        self.linear = torch.nn.Linear(features_in, 1)\n",
    "        # self.RELU = torch.nn.ReLU(inplace=True)\n",
    "        self.sigm = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sigm(self.linear(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "def my_resnet():\n",
    "    resnet = model(weights=model_weights.IMAGENET1K_V1)\n",
    "\n",
    "    resnet.fc = finalLayer(resnet.fc.in_features)\n",
    "    return resnet\n",
    "\n",
    "my_net = my_resnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbf55f69-fee1-4b5d-8af7-16162229c832",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): finalLayer(\n",
       "    (linear): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (sigm): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b5a7781-93d8-4efa-a268-cc9cd1af3b03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = [p for p in my_net.parameters() if p.requires_grad]\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.NAdam(\n",
    "    params,\n",
    "    lr=0.01,\n",
    "    weight_decay=0.0005\n",
    ")\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=3,\n",
    "    gamma=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f9787cc-d150-42f4-97b5-897840c46929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, criterion, data_loader, scheduler, epoch, freq_print):\n",
    "    print(f\"Training epoch {epoch}\")\n",
    "    model.train()\n",
    "    for batch_idx, (X, y) in tqdm(enumerate(data_loader), total=int(len(data_loader.dataset) / data_loader.batch_size)):\n",
    "        y = y.flatten().float()\n",
    "        yhat = model(X).flatten()\n",
    "        loss = criterion(yhat, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx %freq_print == 0:\n",
    "            acc = ((yhat > .5) == y).sum() / data_loader.batch_size\n",
    "            print(f'Batch n {batch_idx}')\n",
    "            print(f'Loss: {loss.item():.4f} Accuracy: {acc:.4f} ')\n",
    "\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1589a2d-f071-47a8-8359-e1eb53c85510",
   "metadata": {},
   "source": [
    "# Тренируем модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2781049-6b23-4590-bc70-aa5f014a348c",
   "metadata": {},
   "source": [
    "- СИТУАЦИЯ:\n",
    "\n",
    "- Тренировал модели весь день, пробовал разные вариации - ResNet18, 32, 50, googlenet.\n",
    "\n",
    "    - Глубина файн-тюнинга - 5 эпох. Все из перечисленных моделей выдавали LogLoss на уровне примерно .69\n",
    "\n",
    "- МОИ МЫСЛИ:\n",
    "- У меня есть предположение, что мой код пытался тренировать все слои модели, поскольку батчи учились довольно долго (по сравнению с Керас моделью из второго ноутбука, который приложил)\n",
    "\n",
    "- ВОПРОС:\n",
    "- Подскажите, пожалуйста, в чём мои ошибки? При файн-тюнинге пользовался:\n",
    "    - https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html\n",
    "    - https://www.kaggle.com/code/francescolorenzo/96-fine-tuning-resnet34-with-pytorch#Generating-Predictions-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bdac0d7-7c7d-4e06-941d-50793b2f3768",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                 | 1/390 [00:04<32:18,  4.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch n 0\n",
      "Loss: 0.7853 Accuracy: 0.4688 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|██████████▌                                                                      | 51/390 [04:08<27:19,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch n 50\n",
      "Loss: 0.6946 Accuracy: 0.6250 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|████████████████████▋                                                           | 101/390 [08:28<25:34,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch n 100\n",
      "Loss: 0.6929 Accuracy: 0.5312 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|██████████████████████████████▉                                                 | 151/390 [12:58<21:16,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch n 150\n",
      "Loss: 0.6949 Accuracy: 0.4844 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████████████████████████████████████▌                                           | 178/390 [15:27<18:24,  5.21s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 10\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, optimizer, criterion, data_loader, scheduler, epoch, freq_print)\u001b[0m\n\u001b[0;32m      7\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(yhat, y)\n\u001b[0;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 10\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_idx \u001b[38;5;241m%\u001b[39mfreq_print \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\conda\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\conda\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_one_epoch(my_net, optimizer, criterion, train_loader, lr_scheduler, epoch, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb761e38-51fc-4699-b76a-a3afd43c6fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(model):\n",
    "    # sigm = torch.nn.Sigmoid()\n",
    "    result = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, _ in tqdm(test_loader):\n",
    "            output = model(x).flatten().tolist()\n",
    "            result += output\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e840d5c5-b4eb-45aa-9afb-d0d206bde2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = make_submission(my_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37591d64-8af4-4439-bcbd-776b1ba41579",
   "metadata": {},
   "source": [
    "# Make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8848ac0e-3d34-4f0a-96e2-f229e952a709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7262622c-0835-4c45-953e-9ae1ce665bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dab3cc-bcdb-483d-af45-0b5f3c26df16",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df['label'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a24189-d497-4afa-b063-e64be76eaa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
